
TransformerMIL4ReceptorPrediction
-----
Transformer and CNN system for the predicion of hormonal receptors from whole slide images, as described in the paper "Clinical Validation of ER, PR, and ERBB2 Status Prediction in Breast Cancer Using Deep Learning on H&E-stained Slides"


Usage
-----

Run preproccessing:
-------------------
        run_preprocess.py [arguments]
    
    Arguments:
        --data_dir            The path to the slides in the published paper.
        
        --tile_size           Required tile size for the generated grid. Default is 256
        
        --tissue_coverage     Minimum tissue percentage for a valid tile.
        
Example
-------
Run with default parameters:

    $ python3 run_preprocess.py --data_dir ./TCGA
    
The script will create two folders inside the slides folders called Grids_10 and SegData which are necessary for training and inference with the cnn


Train the cnn:
--------------
        train_cnn.py [arguments]
    
    Arguments:
        --test_fold           Fold to be used as validation fold while training, can be a number between 0 and 5 or -1 to not perform validation.
                              If the fold is 0, slides with the fold value "test" in the meta data file (described below) will be taken.
        
        --dataset             Path to the slides folder.
        
        --target              Target to train on.
        
        --epochs              Number of training epochs.
        
Run python 3 train_cnn.py -h for more arguments 
        
        
Example
-------
Run with default parameters:

    $ python3 train_cnn.py --test_fold 1 --dataset ./TCGA --target ER
    
In order to train the cnn on a data folder, the folder must contain the slides, as well as the two folders generated by run_preprocess.py as described earlier, as well as a meta data file named slides_data.xlsx.
The meta data file must have a row for each slide and the following columns:

 - "file": filename of the slide

for each label that is a training objective:
 - "<label name> status": either "Positive" or "Negative" or a numerical value or something else ("Missing Data", "Equivocal", etc...) according to the slide status, for example "ER status". 
If the slide label is not "Positive" or "Negative" or numerical it will not be included in training or inference of that target

 - "test fold idx": 1,2,3,4,5 for training and validation, "test" for test set, or "Missing Data" to exclude from training and inference
 
The script will create a folder named "Runs" if it doesn't exist yet, and in it will be all the results from all runs.
The folder Runs will contain a file called run_data.xlsx in it which documents all the runs performed, a folder called run_data_backup which holds previous versions of said file, and a folder for every run.
The folder for every run will be named according to the format Exp_<#>-<target>-TestFold_<#>, for example Exp_1-ER-TestFold_1 and it will contain the model checkpoints, run logs, and backup data.


Extract features with cnn:
--------------------------
        inference_cnn.py [arguments]
    
    Arguments:
        --experiment          Experiment number to be used, according to the number given by the train_cnn.py script as described earlier.
        
        --from_epoch          Number of epoch from which to take the model checkpoint, must be a number for which a checkpoint exists in the checkpoints folder of the experiment folder.
                              can be -1 for the last checkpoint.
        
        --dataset             Path to the slides folder.
        
        --num_tiles           How many tiles to extract for every slide.
        
        --save_features       If given it will save the features extracted for every tile, otherwise will just perform inference and calculate accuracy and auc.
        
        --folds               Perform inference only to the slides from the folds specified in this argument.
                              Each single digit will be considered as a seperate fold.
                              
        --subdir              Sub directory name for the inference results, useful when running inference several times from the same run.
        
        --target              target to perform inference for, only slides with a valid label for this target will be taken.
        
Run python 3 inference_cnn.py -h for more arguments 
        
        
Example
-------
Run with default parameters:

    $ python3 inference_cnn.py --experiment 1 --from_epoch -1 --dataset ./TCGA --num_tiles 500 --save_features --folds 2345 --subdir TCGA_train_features --target ER
    
The script will create a folder named "Inference" if it doesn't already exist in the folder associated with the experiment number provided, in it the script will create a folder with the name provided by the argument --subdir if it was provided, and in it the script will save the inference results and extracted features.

Features extracted for the train and validation sets must be in different folders otherwise the transformer training script will not be able to differentiate between them.


Train the transformer:
----------------------
        train_mil_transformer.py [arguments]
    
    Arguments:
        --exp_name            Experiment name for logging.
        
        --train_features_dir  Path to the train features that were generated with inference_cnn.py
        
        --test_features_dir   Path to the test or validation features that were generated with inference_cnn.py
        
        --dataset             Path to the slides folder.
        
        --target              target to perform inference for, only slides with a valid label for this target will be taken.
        
        --wandb               If provided, will perform logging with wandb, and will create a wandb project named "MIL-Transformer" for all the experiments performed.
                              If not provided, will use tensorboard for offline logging.
                              
        --user                Wandb user name if using wandb.                             
        
Run python 3 train_mil_transformer.py -h for more arguments 
        
        
Example
-------
Run with default parameters:

    $ python3 train_mil_transformer.py --dataset ./TCGA --target ER --exp_name miltransformer_TCGA --train_features_dir ./runs/Exp_1-ER-TestFold_1/Inference/TCGA_train_features/ --test_features_dir ./runs/Exp_1-ER-TestFold_1/Inference/TCGA_test_features/
    
Run with wandb:

    $ python3 train_mil_transformer.py --dataset ./TCGA --target ER --exp_name miltransformer_TCGA --train_features_dir ./runs/Exp_1-ER-TestFold_1/Inference/TCGA_train_features/ --test_features_dir ./runs/Exp_1-ER-TestFold_1/Inference/TCGA_test_features/ --wandb --user shachar5020
    
If using wandb the experiment will be logged online, otherwise it will use tensorboard to log it locally and will create the path "./lightning_logs/MilTransformer/" and in it a folder with the provided experiment name, and a folder with the name "version_<#>" to differentiate between different runs done with the same name. In this folder will be another folder called "checkpoints" inside of which the model checkpoints will be saved.


Run inference with the transformer:
-----------------------------------
        train_mil_transformer.py --test [arguments]
    
    Arguments:
        --exp_name            Experiment name for logging.
        
        --ckpt_path           Checkpoint path of the model to use for inference, if using wandb it should be of the format "wandb:<run id>:<artifact name>" for example "wandb:jhrfernu:best_k", otherwise path to the locally saved checkpoint.
        
        --test_features_dir   Path to the test or validation features that were generated with inference_cnn.py
        
        --test_dataset        Path to the slides folder.
        
        --target              target to perform inference for, only slides with a valid label for this target will be taken.
        
        --wandb               If provided, will perform logging with wandb, and will create a wandb project named "MIL-Transformer" for all the experiments performed.
                              If not provided, will use tensorboard for offline logging.
                              
        --user                Wandb user name if using wandb.
        
        --test                If provided will only run inference with a given checkpoint.                             
        
        
Example
-------
Run with default parameters:

    $ python3 train_mil_transformer.py --test --test_dataset ./TCGA --target ER --ckpt_path "./lightning_logs/MilTransformer/miltransformer_TCGA/version_0/checkpoints/epoch=0-val_auc=0.628.ckpt" --exp_name test_inference --test_features_dir ./runs/Exp_1-ER-TestFold_1/Inference/TCGA_test_features/
    
Run with wandb:

    $ python3 train_mil_transformer.py --test --test_dataset ./TCGA --target ER --ckpt_path "wandb:jhrfernu:best_k" --exp_name test_inference --test_features_dir ./runs/Exp_1-ER-TestFold_1/Inference/TCGA_test_features/ --user shachar5020


Requirements
------- 

To install the requirements, use:
    
    $ conda env create -f environment.yml