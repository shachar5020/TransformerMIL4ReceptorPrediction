
TransformerMIL4ReceptorPrediction
-----
A transformer-based multiple instance learning for the prediction of receptor status from H&E-stained whole slide images. This repository provides training and testing scripts for the article "Clinical Validation of ER, PR, and ERBB2 Status Prediction in Breast Cancer Using Deep Learning on H&E-stained Slides".
An example data directory with the required metadata file can be found at: https://technionmail-my.sharepoint.com/:f:/g/personal/shacharcohen_campus_technion_ac_il/EjGRX7u-li1NnUIXZOJ3oxUBU-mpHpDBf3eeFF0bl6t1QA?e=Wop3mt


Usage
-----

1) Run preproccessing:
-------------------
        run_preprocess.py [arguments]
    
    Arguments:
        --data_dir            The path to the slides.
        
        --tile_size           Required tile size (Default 256).
        
        --tissue_coverage     Minimum tissue percentage for a valid tile (Default 0.3).
        
Example
-------
Run with default parameters:

    $ python3 run_preprocess.py --data_dir ./TCGA
    
The script will create two folders inside the slides folders called Grids_10 and SegData which are necessary for training and inference with the CNN.


2) Train the CNN:
--------------
        train_cnn.py [arguments]
    
    Arguments:
        --test_fold           Fold to be used as validation:
                                    When setting to 1,2,3,4 or 5, the training is done on all folds 1-5 but the test_fold, and testing is done on fold = 'test_fold'.
                                    When setting to 0, the training is done on all folds 1-5, and testing is done on the fold = 'test'
                                    When setting to -1, the training is done on all folds 1-5, without testing.
                                     on can be a number between 0 and 5 or -1 to not perform validation.
                              If the fold is 0, slides with the fold value "test" in the meta data file (described below) will be taken.
        
        --dataset             Path to the slides folder.
        
        --target              Target to train on. For example 'ER'.
        
        --epochs              Number of training epochs (Default 1000).
        
Run python3 train_cnn.py -h for more arguments
        
        
Example
-------
Run with default parameters:

    $ python3 train_cnn.py --test_fold 1 --dataset ./TCGA --target ER
    
In order to train the CNN on a data folder, the folder must contain the slides, the two folders generated by run_preprocess.py as described earlier, and a metadata file named slides_data.xlsx. This metadata file must have a row for each slide, and the following columns with filled values:

 - "file": filename of the slide (with extension)


 - "<target> status": where <target> is 'ER', 'PR', or 'Her2'. The value should be either "Positive" or "Negative". Any other test will be considered as missing data.

 - "test fold idx": 1,2,3,4,5 for cross-validation folds, "test" for test set, or "Missing Data" to exclude from training and inference
 
The script will create a folder named "Runs" if it doesn't exist yet, which contains the results from all runs.
This folder will also contain a file called run_data.xlsx with a documentation of all the runs performed, a folder run_data_backup which holds previous versions of said file, and a folder for every run.
The folder for every run will be named according to the format Exp_<#>-<target>-TestFold_<#> (for example: Exp_1-ER-TestFold_1), and will contain the model checkpoints, run logs, and backup data.


3) Extract features with CNN:
--------------------------
        inference_cnn.py [arguments]
    
    Arguments:
        --experiment          Experiment number to be used, according to the number given by the train_cnn.py script as described earlier.
        
        --from_epoch          Number of epoch from which to take the model checkpoint. This must be a number for which a checkpoint exists in the checkpoints folder of the experiment folder.
                              can be -1 for the last checkpoint.
        
        --dataset             Path to the slides folder.
        
        --num_tiles           How many tiles to extract for every slide.
        
        --save_features       If given it will save the features extracted for every tile, otherwise will just perform inference and calculate accuracy and auc.
        
        --folds               Perform inference only to the slides from the folds specified in this argument.
                              Each single digit will be considered as a seperate fold.
                              
        --subdir              Sub directory name for the inference results, useful when running inference several times from the same run.
        
        --target              target to perform inference for, only slides with a valid label for this target will be taken.
        
Run python3 inference_cnn.py -h for more arguments 
        
        
Example
-------
Run with default parameters:

    $ python3 inference_cnn.py --experiment 1 --from_epoch -1 --dataset ./TCGA --num_tiles 500 --save_features --folds 2345 --subdir TCGA_train_features --target ER
    
The script will create a folder named "Inference" if it doesn't already exist in the folder associated with the experiment number provided, in it the script will create a folder with the name provided by the argument --subdir if it was provided, and in it the script will save the inference results and extracted features.

Features extracted for the train and validation sets must be in different folders otherwise the transformer training script will not be able to differentiate between them.


4) Train the transformer:
----------------------
        train_mil_transformer.py [arguments]
    
    Arguments:
        --exp_name            Experiment name for logging.
        
        --train_features_dir  Path to the train features that were generated with inference_cnn.py
        
        --test_features_dir   Path to the test or validation features that were generated with inference_cnn.py
        
        --dataset             Path to the slides folder.
        
        --target              Target to train on, only slides with a valid label for this target will be taken.
        
        --wandb               If provided, will perform logging with wandb, and will create a wandb project named "MIL-Transformer" for all the experiments performed.
                              If not provided, will use tensorboard for offline logging.
                              
        --user                Wandb user name if using wandb.                             
        
Run python3 train_mil_transformer.py -h for more arguments 
        
        
Example
-------
Run with default parameters:

    $ python3 train_mil_transformer.py --dataset ./TCGA --target ER --exp_name miltransformer_TCGA --train_features_dir ./runs/Exp_1-ER-TestFold_1/Inference/TCGA_train_features/ --test_features_dir ./runs/Exp_1-ER-TestFold_1/Inference/TCGA_test_features/
    
Run with wandb:

    $ python3 train_mil_transformer.py --dataset ./TCGA --target ER --exp_name miltransformer_TCGA --train_features_dir ./runs/Exp_1-ER-TestFold_1/Inference/TCGA_train_features/ --test_features_dir ./runs/Exp_1-ER-TestFold_1/Inference/TCGA_test_features/ --wandb --user shachar5020
    
If using wandb the experiment will be logged online, otherwise it will use tensorboard to log it locally and will create the path "./lightning_logs/MilTransformer/" and in it a folder with the provided experiment name, and a folder with the name "version_<#>" to differentiate between different runs done with the same name. In this folder will be another folder called "checkpoints" inside of which the model checkpoints will be saved.


5) Run inference with the transformer:
-----------------------------------
        train_mil_transformer.py --test [arguments]
    
    Arguments:
        --exp_name            Experiment name for logging.
        
        --ckpt_path           Checkpoint path of the model to use for inference, if using wandb it should be of the format "wandb:<run id>:<artifact name>" for example "wandb:jhrfernu:best_k", otherwise path to the locally saved checkpoint.
        
        --test_features_dir   Path to the test or validation features that were generated with inference_cnn.py
        
        --test_dataset        Path to the slides folder.
        
        --target              target to perform inference for, only slides with a valid label for this target will be taken.
        
        --wandb               If provided, will perform logging with wandb, and will create a wandb project named "MIL-Transformer" for all the experiments performed.
                              If not provided, will use tensorboard for offline logging.
                              
        --user                Wandb user name if using wandb.
        
        --test                If provided will only run inference with a given checkpoint.                             
        
        
Example
-------
Run with default parameters:

    $ python3 train_mil_transformer.py --test --test_dataset ./TCGA --target ER --ckpt_path "./lightning_logs/MilTransformer/miltransformer_TCGA/version_0/checkpoints/epoch=0-val_auc=0.628.ckpt" --exp_name test_inference --test_features_dir ./runs/Exp_1-ER-TestFold_1/Inference/TCGA_test_features/
    
Run with wandb:

    $ python3 train_mil_transformer.py --test --test_dataset ./TCGA --target ER --ckpt_path "wandb:jhrfernu:best_k" --exp_name test_inference --test_features_dir ./runs/Exp_1-ER-TestFold_1/Inference/TCGA_test_features/ --user shachar5020


Requirements
------- 

To install the requirements, use:
    
    $ conda env create -f environment.yml
